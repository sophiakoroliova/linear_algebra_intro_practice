# Linear algebra introduction practice

The repository contains practical homework from the course "Incorrect Data Processing Problems".

Please, use NumPy, SciPy, scikit-learn and similar libs to implement the tasks.

## Practices

1. Vectors;
2. Matrices;
3. Linear and affine mappings;
4. Matrix decompositions;
5. Regularization.

## Аналіз результатів та висновки до ЛАБ №5
### Аналіз результатів регресії (на основі датасету Diabetes):
Порівняння метрик показує, що **лінійна регресія** без регуляризації досягає MSE = 2900.19 та R^2 = 0.453, що свідчить про помірну ефективність, але з ризиком перенавчання через відсутність штрафу за великі коефіцієнти. Модель **Ridge з L2-регуляризацією** покращує показники до MSE = 2875.67 та R^2 = 0.457 (менше MSE, вище R^2) зменшуючи амплітуду коефіцієнтів і підвищуючи стійкість до шуму. **Lasso з L1-регуляризацією** демонструє найкращі результати (MSE = 2824.10, R^ = 0.467), оскільки не тільки згладжує коефіцієнти, але й виконує відбір ознак шляхом обнулення менш релевантних.

**Аналіз коефіцієнтів** підтверджує це: у лінійній моделі спостерігаються значні варіації (від -44.31 до 35.02), що вказує на чутливість до колінеарності ознак. У Ridge коефіцієнти згладжені (від -11.03 до 25.77), тоді як у Lasso деякі з них дорівнюють нулю (наприклад, для шостої ознаки), що сприяє інтерпретовності моделі.
Загалом, регуляризація суттєво підвищує узагальнюючу здатність моделі, особливо Lasso, яка є оптимальною для датасетів з потенційною мультиколінеарністю, типових для медичних даних.

### Аналіз результатів класифікації (на основі датасету Breast Cancer):
Метрики точності: **базова логістична регресія** досягає 0.939, що є прийнятним, але нижчим за регуляризовані варіанти. Моделі з **L2- та L1-регуляризацією** обидві показують точність 0.974, демонструючи перевагу завдяки зменшенню ризику перенавчання.

Коефіцієнти без регуляризації мають значну амплітуду (від -304.41 до 324.10), що свідчить про перенавчання. L2-регуляризація згладжує їх (від -1.36 до 0.67), забезпечуючи стабільність. L1-регуляризація обнуляє багато коефіцієнтів (наприклад, перші сім), виконуючи ефективний відбір ознак.

Висновок: регуляризовані моделі перевищують базову за точністю та стійкістю. L1 корисна для інтерпретації в задачах з великою кількістю ознак, тоді як L2 ефективна при корельованих даних. Для медичних датасетів регуляризація є критичною для мінімізації помилок класифікації.

### Загальні висновки
Регуляризація загалом підвищує ефективність моделей, роблячи їх більш стійкими до шуму та мультиколінеарності в даних. L1-регуляризація рекомендується в випадках, коли потрібен відбір ознак для підвищення інтерпретовності, тоді як L2-регуляризація підходить для згладжування коефіцієнтів без втрати інформації. У подальших дослідженнях доцільно проводити детальний пошук гіперпараметрів для оптимізації моделей під конкретні датасети.

## Useful links

* [Introduction to Linear Algebra for Applied Machine Learning with Python](https://pabloinsente.github.io/intro-linear-algebra)
* [Regularization 1](https://github.com/ethen8181/machine-learning/blob/master/regularization/regularization.ipynb)
* [Regularization 2](https://nbviewer.org/github/justmarkham/DAT8/blob/master/notebooks/20_regularization.ipynb)
